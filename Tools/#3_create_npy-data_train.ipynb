{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "NUMBER_OF_OVERLAPS = \"1-12\"  # Specifies the range of overlaps considered in this dataset\n",
    "\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "WORKING_DIR = os.path.join(current_directory, \"..\")\n",
    "\n",
    "PATH_DATA = os.path.join(WORKING_DIR, \"Data\") \n",
    "\n",
    "PATH_CIPHERTEXTS = os.path.join(PATH_DATA, \"2_ciphertexts_train\")\n",
    "PATH_CIPHERTEXTS = os.path.join(PATH_CIPHERTEXTS, NUMBER_OF_OVERLAPS)\n",
    "\n",
    "PATH_TRAINING_DATA = os.path.join(PATH_DATA, \"3_data_npy_train\")\n",
    "\n",
    "# Ensure the directory for storing training data in NumPy format exists\n",
    "os.makedirs(PATH_TRAINING_DATA, exist_ok=True)\n",
    "PATH_TRAINING_DATA = os.path.join(PATH_TRAINING_DATA, NUMBER_OF_OVERLAPS)\n",
    "os.makedirs(PATH_TRAINING_DATA, exist_ok=True)\n",
    "\n",
    "#NUMBER_CORS = multiprocessing.cpu_count()\n",
    "NUMBER_CORS = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cryptool/vasily/M209/m-209-cryptanalysis-main_updated/Tools/../Data\n",
      "/home/cryptool/vasily/M209/m-209-cryptanalysis-main_updated/Tools/..\n"
     ]
    }
   ],
   "source": [
    "print(PATH_DATA)\n",
    "print(WORKING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=500 # Define the length of sequences to be processed\n",
    "\n",
    "def load_data(file):\n",
    "    # Define the possible wheel settings as strings\n",
    "    wheels = [\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\",\n",
    "              \"ABCDEFGHIJKLMNOPQRSTUVXYZ\",\n",
    "              \"ABCDEFGHIJKLMNOPQRSTUVX\",\n",
    "              \"ABCDEFGHIJKLMNOPQRSTU\",\n",
    "              \"ABCDEFGHIJKLMNOPQRS\",\n",
    "              \"ABCDEFGHIJKLMNOPQ\"]\n",
    "\n",
    "\n",
    "    print(f\"loading: {file}\")\n",
    "    with open (file, 'r') as infile:\n",
    "        data = json.load(infile)\n",
    "\n",
    "\n",
    "    x_temp = []\n",
    "    y_temp = []\n",
    "    \n",
    "    # Process each sequence in the data\n",
    "    for i in range(len(data)):\n",
    "        s=data[i][3][:length]\n",
    "        x_temp.append([ord(n) for n in s])\n",
    "        new_wheel_data = []\n",
    "        for j in range(6):\n",
    "            new_wheel_data += [1 if a in data[i][4][j] else 0 for a in wheels[j]]\n",
    "        y_temp.append(new_wheel_data)\n",
    "    \n",
    "    # Convert the lists to NumPy arrays for use in machine learning models\n",
    "    x = np.array(x_temp, dtype='ubyte')\n",
    "\n",
    "    y = np.array(y_temp, dtype='ubyte')\n",
    "    \n",
    "    # Extract file name and overlaps information for saving\n",
    "    file= file.split('/')[-1]\n",
    "    NUMBER_OF_OVERLAPS = file.split('_')[2].split('.')[0]\n",
    "    file = file.split('_')[0]\n",
    "\n",
    "     # Save the processed data as NumPy arrays\n",
    "    np.save(f\"{PATH_TRAINING_DATA  + '/'}{file}_x_{length}_{NUMBER_OF_OVERLAPS}_.npy\", x)\n",
    "    np.save(f\"{PATH_TRAINING_DATA  + '/'}{file}_y_ALL_{NUMBER_OF_OVERLAPS}_.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = [PATH_CIPHERTEXTS  + '/' + file for file in os.listdir(PATH_CIPHERTEXTS + '/') if \"_cipher\" in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " os.listdir(PATH_CIPHERTEXTS + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cryptool/vasily/M209/m-209-cryptanalysis-main_updated/Tools/../Data/2_ciphertexts_train/1-12\n"
     ]
    }
   ],
   "source": [
    "print (PATH_CIPHERTEXTS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use multiprocessing to process files in parallel for efficiency \n",
    "with multiprocessing.Pool(NUMBER_CORS) as pool:\n",
    "    for _ in pool.imap(load_data, filelist):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory to the training data directory\n",
    "os.chdir(PATH_TRAINING_DATA)\n",
    "x_files = [file for file in os.listdir(PATH_TRAINING_DATA) if 'x' in file]\n",
    "y_files = [file for file in os.listdir(PATH_TRAINING_DATA) if 'y' in file]\n",
    "def test1():\n",
    "    x = np.load(f\"3_training-data_2/{random.choice(x_files)}\")\n",
    "    y = np.load(f\"3_training-data_2/{random.choice(y_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['025_x_500_1-12_.npy', '061_x_500_1-12_.npy', '047_x_500_1-12_.npy', '048_x_500_1-12_.npy', '029_x_500_1-12_.npy', '046_x_500_1-12_.npy', '044_x_500_1-12_.npy', '038_x_500_1-12_.npy', '007_x_500_1-12_.npy', '060_x_500_1-12_.npy', '017_x_500_1-12_.npy', '033_x_500_1-12_.npy', '036_x_500_1-12_.npy', '019_x_500_1-12_.npy', '023_x_500_1-12_.npy', '051_x_500_1-12_.npy', '024_x_500_1-12_.npy', '005_x_500_1-12_.npy', '010_x_500_1-12_.npy', '003_x_500_1-12_.npy', '063_x_500_1-12_.npy', '004_x_500_1-12_.npy', '045_x_500_1-12_.npy', '059_x_500_1-12_.npy', '018_x_500_1-12_.npy', '052_x_500_1-12_.npy', '057_x_500_1-12_.npy', '055_x_500_1-12_.npy', '012_x_500_1-12_.npy', '035_x_500_1-12_.npy', '053_x_500_1-12_.npy', '034_x_500_1-12_.npy', '021_x_500_1-12_.npy', '027_x_500_1-12_.npy', '028_x_500_1-12_.npy', '000_x_500_1-12_.npy', '011_x_500_1-12_.npy', '030_x_500_1-12_.npy', '020_x_500_1-12_.npy', '037_x_500_1-12_.npy', '054_x_500_1-12_.npy', '043_x_500_1-12_.npy', '050_x_500_1-12_.npy', '006_x_500_1-12_.npy', '042_x_500_1-12_.npy', '022_x_500_1-12_.npy', '002_x_500_1-12_.npy', '031_x_500_1-12_.npy', '041_x_500_1-12_.npy', '039_x_500_1-12_.npy', '049_x_500_1-12_.npy', '013_x_500_1-12_.npy', '026_x_500_1-12_.npy', '001_x_500_1-12_.npy', '062_x_500_1-12_.npy', '058_x_500_1-12_.npy', '056_x_500_1-12_.npy', '008_x_500_1-12_.npy', '009_x_500_1-12_.npy', '032_x_500_1-12_.npy', '015_x_500_1-12_.npy', '014_x_500_1-12_.npy', '040_x_500_1-12_.npy', '016_x_500_1-12_.npy']\n"
     ]
    }
   ],
   "source": [
    "print(x_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_files = [file for file in os.listdir(PATH_TRAINING_DATA) if 'x' in file]\n",
    "y_files = [file for file in os.listdir(PATH_TRAINING_DATA) if 'y' in file]\n",
    "\n",
    "# Functions for testing and validating the generated datasets\n",
    "def test1():\n",
    "    x = np.load(f\"{random.choice(x_files)}\")\n",
    "    x = np.array(x, dtype='float32')\n",
    "    x = np.subtract(x,65)\n",
    "    x = np.divide(x , 25)\n",
    "    \n",
    "\n",
    "    y = np.load(f\"{random.choice(y_files)}\")\n",
    "    y = np.array(y, dtype='float32')\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83. 83. 87. ... 66. 83. 67.]\n",
      " [90. 90. 89. ... 72. 78. 88.]\n",
      " [79. 79. 72. ... 70. 82. 75.]\n",
      " ...\n",
      " [73. 73. 84. ... 87. 68. 89.]\n",
      " [90. 90. 84. ... 83. 77. 74.]\n",
      " [70. 70. 81. ... 67. 88. 83.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 1. 0.]\n",
      " [1. 1. 1. ... 1. 0. 1.]\n",
      " [0. 1. 1. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
